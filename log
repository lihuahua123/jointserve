/usr/local/lib/python3.11/dist-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.
  "cipher": algorithms.TripleDES,
/usr/local/lib/python3.11/dist-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.
  "class": algorithms.TripleDES,
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
INFO:server:Set CUDA_VISIBLE_DEVICES to 0
INFO:server:http://0.0.0.0:30000, ports: PortArgs(tokenizer_port=10000, router_port=10001, detokenizer_port=10002, nccl_port=10003, migrate_port=10004, model_rpc_ports=[10005, 10006, 10007])
INFO:model_rpc:Use sleep forwarding: False
INFO:model_rpc:schedule_heuristic: fcfs
INFO:model_runner:Rank 0: load weight begin.
INFO:model_runner:Rank 0: load weight end.
INFO:model_runner:kv one token size: 32 * 128 * 32 * 2 * 2 = 524288 bytes
INFO:model_runner:kv one token size: 32 * 128 * 32 * 2 * 2 = 524288 bytes
INFO:model_runner:self.max_total_num_token,self.max_cpu_num_token 12606,226821
INFO:infer_adapter:load 2 adapters, 2 in total
INFO:model_rpc:Rank 0: max_total_num_token=12606, max_prefill_num_token=33768, context_len=33768, 
INFO:model_rpc:server_args: enable_flashinfer=True, attention_reduce_in_fp32=False, disable_radix_cache=False, disable_regex_jump_forward=False, disable_disk_cache=False, 
/root/jointserve/python/sglang/srt/managers/router/model_rpc.py:724: UserWarning: Warning: available_size=12478, max_total_num_token=12606
KV cache pool leak detected!
  warnings.warn(
INFO:infer_adapter:load 1 adapters, 2 in total
/root/jointserve/python/sglang/srt/managers/router/model_rpc.py:724: UserWarning: Warning: available_size=12542, max_total_num_token=12606
KV cache pool leak detected!
  warnings.warn(
INFO:model_rpc:#running-req: 1, #token: 83, token usage: 0.01, gen throughput (token/s): 6.43, #queue-req: 0
INFO:     Started server process [22161]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)
No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:540,num_tokens:24
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:64,num_tokens:24
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:148,num_tokens:24
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:24
INFO:model_rpc:GPU 0: decode out of memory happened, #retracted_reqs: 1, #new_token_ratio: 0.3201 -> 0.3701
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:23
INFO:model_rpc:GPU 0: decode out of memory happened, #retracted_reqs: 1, #new_token_ratio: 0.3693 -> 0.4193
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:236,num_tokens:21
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:238,num_tokens:20
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:20
INFO:model_rpc:GPU 0: decode out of memory happened, #retracted_reqs: 1, #new_token_ratio: 0.4160 -> 0.4660
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:266,num_tokens:18
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:18
INFO:model_rpc:GPU 0: decode out of memory happened, #retracted_reqs: 1, #new_token_ratio: 0.4632 -> 0.5132
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:17
INFO:model_rpc:GPU 0: decode out of memory happened, #retracted_reqs: 1, #new_token_ratio: 0.5117 -> 0.5617
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:311,num_tokens:15
model /hy-tmp/ loaded.
lora manager ready.
len(self.forward_queue): 1
have waiting requests can schedule,scheduing req len: 1 0.000362396240234375 0.0003638267517089844
offload 2 adapters, 0 remains
offload 1 adapters, 1 remains
len(self.forward_queue): 1
have waiting requests can schedule,scheduing req len: 1 0.024869441986083984 0.0004203319549560547
offload 2 adapters, 0 remains
offload 1 adapters, 1 remains
len(self.forward_queue): 1
have waiting requests can schedule,scheduing req len: 1 0.04538416862487793 0.0002694129943847656
offload 1 adapters, 0 remains
len(self.forward_queue): 1
have waiting requests can schedule,scheduing req len: 1 0.06518983840942383 0.0003590583801269531
offload 1 adapters, 0 remains
len(self.forward_queue): 1
have waiting requests can schedule,scheduing req len: 1 0.7765758037567139 0.0003085136413574219
len(self.forward_queue): 1
have waiting requests can schedule,scheduing req len: 1 0.776864767074585 0.0002894401550292969
len(self.forward_queue): 5
have waiting requests can schedule,scheduing req len: 5 0.7859735488891602 0.0007300376892089844
len(self.forward_queue): 1
have waiting requests can schedule,scheduing req len: 1 0.7862839698791504 0.00031113624572753906
len(self.forward_queue): 3
have waiting requests can schedule,scheduing req len: 3 0.8003931045532227 0.0005028247833251953
len(self.forward_queue): 2
have waiting requests can schedule,scheduing req len: 2 0.8007724285125732 0.00037980079650878906
len(self.forward_queue): 5
have waiting requests can schedule,scheduing req len: 5 0.801630973815918 0.0008592605590820312
len(self.forward_queue): 3
have waiting requests can schedule,scheduing req len: 3 0.802109956741333 0.00047969818115234375
len(self.forward_queue): 2
have waiting requests can schedule,scheduing req len: 1 0.8024570941925049 0.0003478527069091797
len(self.forward_queue): 2
have waiting requests can schedule,scheduing req len: 1 0.802821159362793 0.00036454200744628906
len(self.forward_queue): 1
have waiting requests can schedule,scheduing req len: 1 0.8031091690063477 0.0002884864807128906
len(self.forward_queue): 2
have waiting requests but can't schedule 0.8034534454345703 0.00034737586975097656
len(self.forward_queue): 6
have waiting requests can schedule,scheduing req len: 1 0.8244543075561523 0.0006673336029052734
len(self.forward_queue): 5
have waiting requests can schedule,scheduing req len: 1 0.8250284194946289 0.0005745887756347656
len(self.forward_queue): 4
have waiting requests but can't schedule 0.8255472183227539 0.0005199909210205078
len(self.forward_queue): 4
have waiting requests but can't schedule 0.8463010787963867 0.00052642822265625
len(self.forward_queue): 4
have waiting requests but can't schedule 0.868004322052002 0.0006783008575439453
len(self.forward_queue): 4
have waiting requests but can't schedule 0.8899714946746826 0.0005514621734619141
len(self.forward_queue): 4
have waiting requests but can't schedule 0.9121904373168945 0.0005843639373779297
len(self.forward_queue): 4
have waiting requests but can't schedule 0.933600664138794 0.0005125999450683594
offload 0 adapters, 1 remains
len(self.forward_queue): 4
have waiting requests but can't schedule 0.9542267322540283 0.0005042552947998047
len(self.forward_queue): 4
have waiting requests but can't schedule 0.9747211933135986 0.0005257129669189453
len(self.forward_queue): 4
have waiting requests but can't schedule 0.9954030513763428 0.0005178451538085938
len(self.forward_queue): 4
have waiting requests but can't schedule 1.0152251720428467 0.0005326271057128906
len(self.forward_queue): 4
have waiting requests but can't schedule 1.0359776020050049 0.0006923675537109375
len(self.forward_queue): 4
have waiting requests but can't schedule 1.0566554069519043 0.00052642822265625
len(self.forward_queue): 4
have waiting requests but can't schedule 1.078185796737671 0.0005130767822265625
len(self.forward_queue): 4
have waiting requests but can't schedule 1.0989351272583008 0.0005354881286621094
len(self.forward_queue): 4
have waiting requests but can't schedule 1.1194734573364258 0.0004801750183105469
len(self.forward_queue): 4
have waiting requests but can't schedule 1.1397514343261719 0.0005130767822265625
len(self.forward_queue): 4
have waiting requests but can't schedule 1.1602020263671875 0.0004832744598388672
len(self.forward_queue): 4
have waiting requests but can't schedule 1.1799488067626953 0.0005078315734863281
offload 0 adapters, 1 remains
len(self.forward_queue): 4
have waiting requests but can't schedule 1.190319299697876 0.0004794597625732422
len(self.forward_queue): 4
have waiting requests but can't schedule 1.2007830142974854 0.0006804466247558594
len(self.forward_queue): 4
have waiting requests but can't schedule 1.2212190628051758 0.0004715919494628906
len(self.forward_queue): 4
have waiting requests but can't schedule 1.2408447265625 0.000514984130859375
len(self.forward_queue): 4
have waiting requests but can't schedule 1.260981559753418 0.00047707557678222656
len(self.forward_queue): 4
have waiting requests but can't schedule 1.280411720275879 0.00047278404235839844
cuda
cuda
num_gpu_evicted:540,num_tokens:24
len(self.forward_queue): 4
have waiting requests but can't schedule 1.6269404888153076 0.0005075931549072266
len(self.forward_queue): 4
have waiting requests but can't schedule 1.646841049194336 0.0005705356597900391
cuda
num_gpu_evicted:64,num_tokens:24
len(self.forward_queue): 4
have waiting requests but can't schedule 1.6891319751739502 0.0005137920379638672
cuda
num_gpu_evicted:148,num_tokens:24
num_gpu_evicted:0,num_tokens:24
len(self.forward_queue): 5
have waiting requests but can't schedule 1.7533485889434814 0.0005412101745605469
len(self.forward_queue): 5
have waiting requests but can't schedule 1.7732560634613037 0.0005669593811035156
num_gpu_evicted:0,num_tokens:23
offload 0 adapters, 1 remains
len(self.forward_queue): 6
have waiting requests but can't schedule 1.7863757610321045 0.0005970001220703125
len(self.forward_queue): 6
have waiting requests but can't schedule 1.7966156005859375 0.0006229877471923828
cuda
num_gpu_evicted:236,num_tokens:21
offload 0 adapters, 1 remains
len(self.forward_queue): 6
have waiting requests but can't schedule 1.879060983657837 0.0006160736083984375
len(self.forward_queue): 6
have waiting requests but can't schedule 1.8845605850219727 0.0008831024169921875
cuda
num_gpu_evicted:238,num_tokens:20
len(self.forward_queue): 6
have waiting requests but can't schedule 1.9917325973510742 0.0006277561187744141
len(self.forward_queue): 6
have waiting requests but can't schedule 2.0109307765960693 0.0006389617919921875
num_gpu_evicted:0,num_tokens:20
len(self.forward_queue): 7
have waiting requests but can't schedule 2.0327019691467285 0.0006937980651855469
offload 0 adapters, 1 remains
len(self.forward_queue): 7
have waiting requests but can't schedule 2.0377817153930664 0.0006470680236816406
len(self.forward_queue): 7
have waiting requests but can't schedule 2.051384449005127 0.0006992816925048828
cuda
num_gpu_evicted:266,num_tokens:18
len(self.forward_queue): 7
have waiting requests but can't schedule 2.1627707481384277 0.0006682872772216797
num_gpu_evicted:0,num_tokens:18
len(self.forward_queue): 8
have waiting requests but can't schedule 2.1856369972229004 0.0007748603820800781
len(self.forward_queue): 8
have waiting requests but can't schedule 2.2039947509765625 0.0007870197296142578
num_gpu_evicted:0,num_tokens:17
len(self.forward_queue): 9
have waiting requests but can't schedule 2.224398374557495 0.0007627010345458984
offload 0 adapters, 1 remains
len(self.forward_queue): 9
have waiting requests but can't schedule 2.239055871963501 0.0007991790771484375
len(self.forward_queue): 9
have waiting requests but can't schedule 2.241875410079956 0.0008280277252197266
len(self.forward_queue): 9
have waiting requests but can't schedule 2.2589778900146484 0.0007805824279785156
cuda
num_gpu_evicted:311,num_tokens:15
len(self.forward_queue): 9
have waiting requests but can't schedule 2.415311574935913 0.0008242130279541016
len(self.forward_queue): 9
have waiting requests but can't schedule 2.43276309967041 0.0008108615875244141
len(self.forward_queue): 9INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:15
INFO:model_rpc:GPU 0: decode out of memory happened, #retracted_reqs: 1, #new_token_ratio: 0.5577 -> 0.6077
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:14
INFO:model_rpc:GPU 0: decode out of memory happened, #retracted_reqs: 1, #new_token_ratio: 0.6053 -> 0.6553
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:384,num_tokens:14
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:412,num_tokens:14
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:900,num_tokens:14
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:464,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0

have waiting requests but can't schedule 2.4497342109680176 0.0008835792541503906
num_gpu_evicted:0,num_tokens:15
len(self.forward_queue): 10
have waiting requests but can't schedule 2.4690544605255127 0.0008568763732910156
len(self.forward_queue): 10
have waiting requests but can't schedule 2.4875130653381348 0.0009176731109619141
len(self.forward_queue): 10
have waiting requests but can't schedule 2.504289388656616 0.0008854866027832031
num_gpu_evicted:0,num_tokens:14
len(self.forward_queue): 11
have waiting requests but can't schedule 2.524266481399536 0.0010700225830078125
offload 0 adapters, 1 remains
len(self.forward_queue): 11
have waiting requests can schedule,scheduing req len: 1 2.5419509410858154 0.001689910888671875
len(self.forward_queue): 10
have waiting requests can schedule,scheduing req len: 1 2.5429654121398926 0.0010149478912353516
len(self.forward_queue): 9
have waiting requests but can't schedule 2.544005870819092 0.0010418891906738281
len(self.forward_queue): 9
have waiting requests but can't schedule 2.562418222427368 0.000873565673828125
cuda
num_gpu_evicted:384,num_tokens:14
len(self.forward_queue): 9
have waiting requests but can't schedule 2.7829065322875977 0.0009069442749023438
offload 0 adapters, 1 remains
len(self.forward_queue): 9
have waiting requests can schedule,scheduing req len: 1 2.791630506515503 0.0009241104125976562
len(self.forward_queue): 8
have waiting requests but can't schedule 2.7924087047576904 0.0007791519165039062
len(self.forward_queue): 8
have waiting requests but can't schedule 2.8008816242218018 0.0008647441864013672
len(self.forward_queue): 8
have waiting requests but can't schedule 2.817983388900757 0.0008637905120849609
cuda
num_gpu_evicted:412,num_tokens:14
len(self.forward_queue): 8
have waiting requests but can't schedule 2.964492082595825 0.0008480548858642578
len(self.forward_queue): 8
have waiting requests but can't schedule 2.9811062812805176 0.0009098052978515625
len(self.forward_queue): 8
have waiting requests but can't schedule 2.997882127761841 0.0008168220520019531
len(self.forward_queue): 8
have waiting requests but can't schedule 3.0140788555145264 0.0008189678192138672
cuda
num_gpu_evicted:900,num_tokens:14
offload 0 adapters, 1 remains
len(self.forward_queue): 8
cuda
num_gpu_evicted:464,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 15, left 885
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 525, left 360
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 64, left 296
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 148, left 148
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 236, left -88
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 238, left 662
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 266, left 396
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 311, left 85
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 384, left -299
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:702,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 702, left 198
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 412, left -214
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:pass the evicted GPU for need_to_evicted_cpu > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 464, left 436
INFO:sglang.srt.managers.router.radix_cache:evicted_cpu_token: 900, left -464
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:0,num_tokens:900
ERROR:model_rpc:Exception in ModelRpcClient:
Traceback (most recent call last):
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 319, in exposed_step
    self.forward_step()
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 665, in forward_step
    new_batch = self.get_new_fill_batch()
                ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 1029, in get_new_fill_batch
    self.check_req_hit(self.forward_queue)
  File "/root/jointserve/python/sglang/srt/managers/router/model_rpc.py", line 814, in check_req_hit
    prefix_indices = torch.concat(prefix_indices_list)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)

INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:199,num_tokens:12
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:302,num_tokens:12
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:x.lock_ref > 0
INFO:sglang.srt.managers.router.radix_cache:GPU move to cpu
INFO:sglang.srt.managers.router.radix_cache:num_gpu_evicted:328,num_tokens:12
You pressed Ctrl+C! Shutting down all remote servers...
INFO:     Shutting down

len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
cuda
num_gpu_evicted:702,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
num_gpu_evicted:0,num_tokens:900
len(self.forward_queue): 8
have waiting requests but can't schedule 3.392786979675293 0.0007517337799072266
len(self.forward_queue): 8
have waiting requests but can't schedule 3.4100217819213867 0.00078582763671875
len(self.forward_queue): 8
have waiting requests but can't schedule 3.4264659881591797 0.0007367134094238281
len(self.forward_queue): 8
have waiting requests but can't schedule 3.4417457580566406 0.0007207393646240234
len(self.forward_queue): 8
have waiting requests but can't schedule 3.4572830200195312 0.0007562637329101562
len(self.forward_queue): 8
have waiting requests but can't schedule 3.473529815673828 0.0007412433624267578
len(self.forward_queue): 8
have waiting requests but can't schedule 3.4895598888397217 0.0007610321044921875
offload 0 adapters, 1 remains
len(self.forward_queue): 8
have waiting requests but can't schedule 3.503692865371704 0.0007047653198242188
len(self.forward_queue): 8
have waiting requests but can't schedule 3.5061516761779785 0.0007145404815673828
len(self.forward_queue): 8
have waiting requests but can't schedule 3.521341562271118 0.0007908344268798828
len(self.forward_queue): 8
have waiting requests but can't schedule 3.5379128456115723 0.0007550716400146484
len(self.forward_queue): 8
have waiting requests but can't schedule 3.5537638664245605 0.0007131099700927734
len(self.forward_queue): 8
have waiting requests but can't schedule 3.5688893795013428 0.0007691383361816406
cuda
cuda
num_gpu_evicted:199,num_tokens:12
len(self.forward_queue): 8
have waiting requests but can't schedule 3.702080726623535 0.0009319782257080078
len(self.forward_queue): 8
have waiting requests but can't schedule 3.7187893390655518 0.0009648799896240234
cuda
num_gpu_evicted:302,num_tokens:12
len(self.forward_queue): 8
have waiting requests but can't schedule 3.888728380203247 0.00080108642578125
len(self.forward_queue): 8
have waiting requests but can't schedule 3.9047696590423584 0.0007944107055664062
len(self.forward_queue): 8
have waiting requests but can't schedule 3.9202160835266113 0.0008177757263183594
cuda
num_gpu_evicted:328,num_tokens:12
len(self.forward_queue): 8
have waiting requests but can't schedule 4.145867347717285 0.0009293556213378906
You pressed Ctrl+C! Shutting down all remote servers...
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [22161]
ERROR:    Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 741, in lifespan
    await receive()
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/lifespan/on.py", line 137, in receive
    return await self.receive_queue.get()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/queues.py", line 158, in get
    await getter
asyncio.exceptions.CancelledError

ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/usr/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1511, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1504, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1377, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 555, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 474, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 68, in serve
    with self.capture_signals():
  File "/usr/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/server.py", line 328, in capture_signals
    signal.raise_signal(captured_signal)
  File "/root/jointserve/preble/multi_node_loader.py", line 36, in runtime_cleanup_handler
    sys.exit(0)
SystemExit: 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 399, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py", line 70, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py", line 65, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 756, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 776, in app
    await route.handle(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 297, in handle
    await self.app(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 77, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/usr/local/lib/python3.11/dist-packages/starlette/routing.py", line 75, in app
    await response(scope, receive, send)
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 265, in __call__
    await wrap(partial(self.listen_for_disconnect, receive))
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 261, in wrap
    await func()
  File "/usr/local/lib/python3.11/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect
    message = await receive()
              ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive
    await self.message_event.wait()
  File "/usr/lib/python3.11/asyncio/locks.py", line 213, in wait
    await fut
asyncio.exceptions.CancelledError
Server is on port 30000 on host 0.0.0.0 on pid 22319
You pressed Ctrl+C! Shutting down all remote servers...
Loading runtimes at ['http://0.0.0.0:30000/generate']
You pressed Ctrl+C! Shutting down all remote servers...
You pressed Ctrl+C! Shutting down all remote servers...
